Content-Type: multipart/mixed; boundary="//"
MIME-Version: 1.0

--//
Content-Type: text/cloud-config; charset="us-ascii"
MIME-Version: 1.0
Content-Transfer-Encoding: 7bit
Content-Disposition: attachment; filename="cloud-config.txt"

#cloud-config
cloud_final_modules:
- [scripts-user, always]

--//
Content-Type: text/x-shellscript; charset="us-ascii"
MIME-Version: 1.0
Content-Transfer-Encoding: 7bit
Content-Disposition: attachment; filename="userdata.txt"

#!/bin/bash
cd /home/ubuntu/git_repo/COVID-19/csse_covid_19_data/csse_covid_19_time_series/
git pull

aws s3 cp time_series_covid19_confirmed_global.csv s3://$DATALAKE_BUCKET/raw/jhu_csse_covid_19/202004140200/jhu_csse_covid_19_time_series_confirmed_global__202004140200__202004140200.csv
aws s3 cp time_series_covid19_deaths_global.csv s3://$DATALAKE_BUCKET/raw/jhu_csse_covid_19/202004140200/jhu_csse_covid_19_time_series_deaths_global__202004140200__202004140200.csv
aws s3 cp time_series_covid19_recovered_global.csv s3://$DATALAKE_BUCKET/raw/jhu_csse_covid_19/202004140200/jhu_csse_covid_19_time_series_recovered_global__202004140200__202004140200.csv

cd /home/ubuntu/spark-2.4.3-bin-spark-2.4.3-bin-hadoop2.8/bin/
./spark-submit --jars /home/ubuntu/jars/aws-java-sdk-1.11.762.jar,/home/ubuntu/jars/hadoop-aws-2.8.0.jar /home/ubuntu/scripts/stage.py
./spark-submit --jars /home/ubuntu/jars/aws-java-sdk-1.11.762.jar,/home/ubuntu/jars/hadoop-aws-2.8.0.jar /home/ubuntu/scripts/daily_feature.py

sudo shutdown -P now

--//